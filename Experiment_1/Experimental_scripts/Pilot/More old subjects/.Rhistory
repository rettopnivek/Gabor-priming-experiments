plot( alpha.val, -alpha.prior, type = 'l',
xlab = ' ', ylab = ' ',
bty = 'n', xaxt = 'n', yaxt = 'n' )
abline( v = true.parameters['alpha'] )
# lines( alpha.val, alpha.start.prior, lty = 2 )
posterior[1:3,1:3]
# Randomly generate a set of true parameters
#true.parameters = c( alpha = runif(1,.5,5),
#										 beta = runif(1,-3,3) )
true.parameters = c(3,3)
# Create a discretized range of sensory levels
x_lev = seq( -7, 0, length = 20 )
# Number of trials to run
N.trials = 80
# Values for the truncated normal priors
priors = c( mu.a = 2, sigma.a = 3, mu.b = 3, sigma.b = 3 )
# Create a discrete set of parameter values to optimize over
alpha.prec = 50; beta.prec = 50; # Number of discrete steps
# Vector of parameter values
boundaries = c( a.lower = 0, a.upper = 7,
b.lower = 0, b.upper = 7 )
alpha.val = seq( boundaries['a.lower'], boundaries['a.upper'],
length = alpha.prec )
beta.val = seq( boundaries['b.lower'], boundaries['b.upper'],
length = beta.prec )
# Determine the prior densities for the discrete values
# We'll use a truncated normal distribution, because the discrete
# approximation has distinct boundaries
alpha.prior = dnorm( alpha.val, priors['mu.a'], priors['sigma.a'] )
alpha.prior = alpha.prior/diff(
pnorm( boundaries[1:2], priors['mu.a'], priors['sigma.a'] ) )
beta.prior = dnorm( beta.val, priors['mu.a'], priors['sigma.a'] )
beta.prior = beta.prior/diff(
pnorm( boundaries[3:4], priors['mu.b'], priors['sigma.b'] ) )
# Save the original starting priors
alpha.start.prior = alpha.prior
beta.start.prior = beta.prior
# Plot the likelihood across range of sensory levels
# x = seq( - 4, 4, length=1000 )
# x11();
# plot( x, f.alpha.beta( x, true.parameters['alpha'],
# 											 true.parameters['beta'] ), type = 'l',
# 			xlab = 'Sensory levels', ylab = 'P(Correct)', bty = 'l',
# 			ylim = c(0,1) )
# Vectors to store output
accuracy = numeric( N.trials )
sensory.levels = numeric( N.trials )
trl = 1
# Define a starting sensory level
x = x_lev[ round(length(x_lev)/2) ];
y=0
accuracy[1] = y; sensory.levels[1] = x;
###
### Subsequent trials
###
# Determine the posterior using a grid approximation method
results = grid.approx( y, x, alpha.val, beta.val,
alpha.prior, beta.prior )
results$posterior[1:3,1:3]
alpha.priors
alpha.prior
round(alpha.prior,4)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
# Randomly generate a set of true parameters
#true.parameters = c( alpha = runif(1,.5,5),
#										 beta = runif(1,-3,3) )
true.parameters = c(3,3)
# Create a discretized range of sensory levels
x_lev = seq( -7, 0, length = 20 )
# Number of trials to run
N.trials = 80
# Values for the truncated normal priors
priors = c( mu.a = 2, sigma.a = 3, mu.b = 3, sigma.b = 3 )
# Create a discrete set of parameter values to optimize over
alpha.prec = 50; beta.prec = 50; # Number of discrete steps
# Vector of parameter values
boundaries = c( a.lower = 0, a.upper = 7,
b.lower = 0, b.upper = 7 )
alpha.val = seq( boundaries['a.lower'], boundaries['a.upper'],
length = alpha.prec )
beta.val = seq( boundaries['b.lower'], boundaries['b.upper'],
length = beta.prec )
# Determine the prior densities for the discrete values
# We'll use a truncated normal distribution, because the discrete
# approximation has distinct boundaries
alpha.prior = dnorm( alpha.val, priors['mu.a'], priors['sigma.a'] )
alpha.prior = alpha.prior/diff(
pnorm( boundaries[1:2], priors['mu.a'], priors['sigma.a'] ) )
beta.prior = dnorm( beta.val, priors['mu.b'], priors['sigma.b'] )
beta.prior = beta.prior/diff(
pnorm( boundaries[3:4], priors['mu.b'], priors['sigma.b'] ) )
# Save the original starting priors
alpha.start.prior = alpha.prior
beta.start.prior = beta.prior
round( beta.prior, 4)
boundaries
# Randomly generate a set of true parameters
#true.parameters = c( alpha = runif(1,.5,5),
#										 beta = runif(1,-3,3) )
true.parameters = c(3,3)
# Create a discretized range of sensory levels
x_lev = seq( -7, 0, length = 20 )
# Number of trials to run
N.trials = 80
# Values for the truncated normal priors
priors = c( mu.a = 2, sigma.a = 3, mu.b = 3.5, sigma.b = 3 )
# Create a discrete set of parameter values to optimize over
alpha.prec = 50; beta.prec = 50; # Number of discrete steps
# Vector of parameter values
boundaries = c( a.lower = 0, a.upper = 7,
b.lower = 0, b.upper = 7 )
alpha.val = seq( boundaries['a.lower'], boundaries['a.upper'],
length = alpha.prec )
beta.val = seq( boundaries['b.lower'], boundaries['b.upper'],
length = beta.prec )
# Determine the prior densities for the discrete values
# We'll use a truncated normal distribution, because the discrete
# approximation has distinct boundaries
alpha.prior = dnorm( alpha.val, priors['mu.a'], priors['sigma.a'] )
alpha.prior = alpha.prior/diff(
pnorm( boundaries[1:2], priors['mu.a'], priors['sigma.a'] ) )
beta.prior = dnorm( beta.val, priors['mu.b'], priors['sigma.b'] )
beta.prior = beta.prior/diff(
pnorm( boundaries[3:4], priors['mu.b'], priors['sigma.b'] ) )
# Save the original starting priors
alpha.start.prior = alpha.prior
beta.start.prior = beta.prior
accuracy = numeric( N.trials )
sensory.levels = numeric( N.trials )
round( beta.prior, 4)
y
x
x = x_lev[ round(length(x_lev)/2) ];
# Determine the posterior using a grid approximation method
results = grid.approx( y, x, alpha.val, beta.val,
alpha.prior, beta.prior )
posterior[1:3,1:3]
alpha.prior
x
y
y = 0
# Determine the posterior using a grid approximation method
results = grid.approx( y, x, alpha.val, beta.val,
alpha.prior, beta.prior )
results$posterior[1:3,1:3]
x11(width=10,height=10);
layout( rbind( c( 2, 1, 1, 1 ),
c( 2, 1, 1, 1 ),
c( 2, 1, 1, 1 ),
c( 4, 3, 3, 3 ) ) )
par( mar = c( 4, 4, 3, 1 ) )
# A plot of the posterior
image( results$posterior, xlab = expression(alpha),
ylab = expression(beta), main = 'Posterior',
xaxt = 'n', yaxt = 'n')
axis(1, seq(0,1,length=5),
round( seq( min(alpha.val), max(alpha.val), length = 5),1) )
axis(2, seq(0,1,length=5),
round( seq( min(beta.val), max(beta.val), length = 5),1) )
x11(width=10,height=10);
layout( rbind( c( 2, 1, 1, 1 ),
c( 2, 1, 1, 1 ),
c( 2, 1, 1, 1 ),
c( 4, 3, 3, 3 ) ) )
par( mar = c( 4, 4, 3, 1 ) )
# A plot of the posterior
image( results$posterior, xlab = expression(alpha),
ylab = expression(beta), main = 'Posterior',
xaxt = 'n', yaxt = 'n')
axis(1, seq(0,1,length=5),
round( seq( min(alpha.val), max(alpha.val), length = 5),1) )
axis(2, seq(0,1,length=5),
round( seq( min(beta.val), max(beta.val), length = 5),1) )
image( t( results$posterior ) )
x11(); image( t( results$posterior ) )
results$posterior[ 15:20,15:20]
round( results$posterior[ 15:20,15:20], 4 )
round( results$alpha.posterior, 4 )
exp( posterior[1:3,1:3] )
round( exp( posterior[1:3,1:3] ), 4 )
exp( posterior[1,1] )
exp( results$posterior[1:3,1:3] )
round( exp( results$posterior[1:3,1:3] ), 2 )
round( exp( results$posterior[1:3,1:3] ), 4 )
rowSums( exp( results$posterior ) )
rowSums( exp( results$posterior ) )/sum( exp( posterior ) )
round( rowSums( exp( results$posterior ) )/sum( exp( posterior ) ), 4 )
round( rowSums( exp( results$posterior ) ), 4 )
round( colSums( exp( results$posterior ) ), 4 )
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
true.parameters
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/Rmarkdown/R_script_grid_approx_2PL.R', echo=TRUE)
source('~/Rmarkdown/R_script_grid_approx_2PL.R', echo=TRUE)
source('~/Rmarkdown/R_script_grid_approx_2PL.R', echo=TRUE)
source('~/Rmarkdown/R_script_grid_approx_2PL.R', echo=TRUE)
source('~/Rmarkdown/R_script_grid_approx_2PL.R', echo=TRUE)
source('~/Rmarkdown/R_script_grid_approx_2PL.R', echo=TRUE)
# Set the maximum number of iterations
total = 10
# Create a progress bar using a base R function
pb = txtProgressBar( min = 0, max = total, style = 2 )
for (i in 1:total) {
Sys.sleep(.1) # Set a ~100 ms delay
# Update the progress bar
setTxtProgressBar(pb,i)
}
close(pb)
# Set the maximum number of iterations
total = 10
# Create a progress bar using a base R function
pb = txtProgressBar( min = 0, max = total, style = 1 )
for (i in 1:total) {
Sys.sleep(.1) # Set a ~100 ms delay
# Update the progress bar
setTxtProgressBar(pb,i)
}
close(pb)
# Set the maximum number of iterations
total = 10
# Create a progress bar using a base R function
pb = txtProgressBar( min = 0, max = total, style = 3 )
for (i in 1:total) {
Sys.sleep(.1) # Set a ~100 ms delay
# Update the progress bar
setTxtProgressBar(pb,i)
}
close(pb)
N <- 200 # Number of points per class
D <- 2 # Dimensionality
K <- 4 # Number of classes
X <- data.frame() # data matrix (each row = single example)
y <- data.frame() # class labels
set.seed(308) # For reproducibility
# Loop through classes
for (j in (1:K)) {
r <- seq(0.05,1,length.out = N) # Radius increases with each point
t <- seq( (j-1)*4.7, j*4.7, length.out = N) + rnorm(N, sd = 0.3) # Theta
Xtemp <- data.frame(x =r*sin(t) , y = r*cos(t))
ytemp <- data.frame(matrix(j, N, 1))
X <- rbind(X, Xtemp)
y <- rbind(y, ytemp)
}
obs <- cbind(X,y)
colnames(obs) <- c(colnames(X), 'label')
x_min <- min(X[,1])-0.2; x_max <- max(X[,1])+0.2
y_min <- min(X[,2])-0.2; y_max <- max(X[,2])+0.2
x11()
plot( c(x_min,x_max), c(y_min,y_max), type = 'n', xlab = ' ',
ylab = ' ', bty = 'l' )
clr = rainbow( length( unique( obs$label ) ) )
points( obs$x, obs$y, pch=19, col = clr[ obs$label ] )
head(X)
head(Y)
X <- as.matrix(X)
Y <- matrix(0, N*K, K)
for (i in 1:(N*K)) {
Y[i, y[i,]] <- 1
}
head(Y)
head(X)
N <- nrow(X) # Determine the number of observations
K <- ncol(Y) # Determine the number of classes
D <- ncol(X) # Dimensionality
N
K
D
10*D
D
matrix( rnorm(D*h), nrow = D )
h = 10
matrix( rnorm(D*h), nrow = D )
matrix(0, nrow = 1, ncol = h)
matrix(rnorm(h*K), nrow = h)
head(X)
W <- 0.01 * matrix( rnorm(D*h), nrow = D )
b <- matrix(0, nrow = 1, ncol = h)
W2 <- 0.01 * matrix(rnorm(h*K), nrow = h)
b2 <- matrix(0, nrow = 1, ncol = K)
dim(W)
X %*% W
N
b
# Randomly initialize parameters
W <- 0.01 * matrix( rnorm(D*h), nrow = D ) # Matrix of weights
b <- matrix(0, nrow = 1, ncol = h)
W2 <- 0.01 * matrix(rnorm(h*K), nrow = h)
b2 <- matrix(0, nrow = 1, ncol = K)
# hidden layer, ReLU activation
hidden_layer <- pmax( 0, X %*% W + matrix( rep(b,N),
nrow = N, byrow = T) )
hidden_layer <- matrix(hidden_layer, nrow = N)
head(hidden_layer
)
head(hidden_layer)
# class score
scores <- hidden_layer %*% W2 + matrix( rep(b2,N),
nrow = N, byrow = T)
head(scores)
head(W2)
dim(hidden_layer)
exp_scores <- exp(scores)
probs <- exp_scores / rowSums(exp_scores)
head(probs)
correct_logprobs <- -log(probs)
data_loss <- sum(corect_logprobs*Y)/N
data_loss <- sum(correct_logprobs*Y)/N
head(data_loss)
nLoops = 1
nA = 1
nE = 3
nBlocks = nLoops*( nA + nE )
nBlocks
nLoops = 2
nA = 1
nE = 3
nBlocks = nLoops*( nA + nE )
nLoops = 2
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nLoops = 2
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nBlocks
nE*nLoops
nE*nLoops*nTotalTrials
nTotalTrials = 80 # Total number of trials
nE*nLoops*nTotalTrials
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
nTotalTrials
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
stepsPsychometric = 20
nTotalTrials/stepsPsychometric
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialsPerStep
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialSet = trialsPerStep/4
trialSet
nLoops = 3
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nBlocks
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialSet = trialsPerStep/4
nLoops = 3
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nBlocks
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialSet = trialsPerStep/4
trialSet
nLoops = 3
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nBlocks
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
nTotalTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialSet = trialsPerStep/4
trialSet
nLoops = 3
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nBlocks
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
nTotalTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialsPerStep
trialSet = trialsPerStep/4
trialSet
nLoops = 3
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nBlocks
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
nTotalTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialsPerStep
trialSet = trialsPerStep/4
trialSet
nLoops = 1
nA = 1
nE = 2
nBlocks = nLoops*( nA + nE )
nBlocks
nBlockTrials = 80 # Number of trials for a block
nTotalTrials = nE*nLoops*nBlockTrials
nTotalTrials
stepsPsychometric = 20
trialsPerStep = nTotalTrials/stepsPsychometric # Number of trials for a step
trialsPerStep
trialSet = trialsPerStep/4
trialSet
setwd("C:/Users/Kevin/Desktop/Gabor_priming_2016/Analyses")
setwd("C:/Users/Kevin/Desktop/Gabor_priming_2016/Subjects")
subjDir = getwd();
fname = 'Subject_3.csv'
fname2 = 'Subject_3.mat'
dat.gabor = read.table( fname,header=T,sep=',')
dat.sel = dat.gabor[ dat.gabor$BlockType>1,]
# Accuracy
ac = aggregate( dat.sel$Accuracy, list(
dat.sel$PrimeDuration,
dat.sel$Target==dat.sel$Prime ), mean )
colnames( ac ) = c('Duration','Prime','P')
x11()
plot( lowerUpper(1, log( ac$Duration ) ),
lowerUpper( .1, ac$P ), type = 'n',
xlab = 'Duration (ms)', ylab = 'Accuracy',
xaxt = 'n', bty = 'n' )
axis(1, log( unique(ac$Duration) ),
unique(ac$Duration) )
library( utilityf )
# Accuracy
ac = aggregate( dat.sel$Accuracy, list(
dat.sel$PrimeDuration,
dat.sel$Target==dat.sel$Prime ), mean )
colnames( ac ) = c('Duration','Prime','P')
x11()
plot( lowerUpper(1, log( ac$Duration ) ),
lowerUpper( .1, ac$P ), type = 'n',
xlab = 'Duration (ms)', ylab = 'Accuracy',
xaxt = 'n', bty = 'n' )
axis(1, log( unique(ac$Duration) ),
unique(ac$Duration) )
# Target was primed
lines( log( ac$Duration[ ac$Prime==T ] ),
ac$P[ ac$Prime==T ], lwd = 2, col = 'green' )
points( log( ac$Duration[ ac$Prime==T ] ),
ac$P[ ac$Prime==T ], pch = 19, col = 'green' )
# Target was not primed
lines( log( ac$Duration[ ac$Prime==F ] ),
ac$P[ ac$Prime==F ], lwd = 2, col = 'red' )
points( log( ac$Duration[ ac$Prime==F ] ),
ac$P[ ac$Prime==F ], pch = 19, col = 'red' )
legend( 'topleft', c( 'Primed', 'Unprimed' ),
fill = c( 'green', 'red' ), bty = 'n' )
rt = aggregate( dat.sel$RT, list(
dat.sel$PrimeDuration,
dat.sel$Target==dat.sel$Prime,
dat.sel$Accuracy ), median )
colnames( rt ) = c('Duration','Prime','Accuracy','RT')
x11()
plot( lowerUpper(1, log( rt$Duration ) ),
lowerUpper( .2, rt$RT ), type = 'n',
xlab = 'Duration (ms)', ylab = 'RT',
xaxt = 'n', bty = 'n' )
axis(1, log( unique(rt$Duration) ),
unique(rt$Duration) )
# Target was primed
lines( log( rt$Duration[ rt$Prime==T & rt$Accuracy == 1 ] ),
rt$RT[ rt$Prime==T & rt$Accuracy == 1 ], lwd = 2, col = 'green' )
points( log( rt$Duration[ rt$Prime==T & rt$Accuracy == 1 ] ),
rt$RT[ rt$Prime==T & rt$Accuracy == 1 ], pch = 19, col = 'green' )
# Target was not primed
lines( log( rt$Duration[ rt$Prime==F & rt$Accuracy == 1 ] ),
rt$RT[ rt$Prime==F & rt$Accuracy == 1 ], lwd = 2, col = 'red' )
points( log( rt$Duration[ rt$Prime==F & rt$Accuracy == 1 ] ),
rt$RT[ rt$Prime==F & rt$Accuracy == 1 ], pch = 19, col = 'red' )
# Target was primed
lines( log( rt$Duration[ rt$Prime==T & rt$Accuracy == 0 ] ),
rt$RT[ rt$Prime==T & rt$Accuracy == 0 ], lwd = 2, lty = 2, col = 'green' )
points( log( rt$Duration[ rt$Prime==T & rt$Accuracy == 0 ] ),
rt$RT[ rt$Prime==T & rt$Accuracy == 0 ], pch = 4, col = 'green' )
# Target was not primed
lines( log( rt$Duration[ rt$Prime==F & rt$Accuracy == 0 ] ),
rt$RT[ rt$Prime==F & rt$Accuracy == 0 ], lwd = 2, lty = 2, col = 'red' )
points( log( rt$Duration[ rt$Prime==F & rt$Accuracy == 0 ] ),
rt$RT[ rt$Prime==F & rt$Accuracy == 0 ], pch = 4, col = 'red' )
legend( 'topleft', c( 'Primed', 'Unprimed' ),
fill = c( 'green', 'red' ), bty = 'n' )
aggregate(dat.sel$Contrast,list(dat.sel$Block) )
aggregate(dat.sel$Contrast,list(dat.sel$Block), uunique)
aggregate(dat.sel$Contrast,list(dat.sel$Block), unique)
mean(dat.sel$Accuracy)
